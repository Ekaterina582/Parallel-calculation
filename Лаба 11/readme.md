1. Постановка задачи
Цель работы:
Реализовать параллельный алгоритм вычисления суммы элементов большого массива с использованием MPI (Message Passing Interface) и сравнить его производительность с последовательной версией.
Задачи:
Разработать программу, которая:
Генерирует массив из 1 000 000 случайных чисел (0-99)
Вычисляет сумму:
Последовательно (на одном процессе)
Параллельно (распределяя вычисления между несколькими процессами)
Сравнить время выполнения двух подходов
Оценить ускорение (speedup) от параллелизации
Ожидаемый результат:
Параллельная версия должна работать быстрее последовательной
Сравнение времени выполнения и расчет ускорения

2. Описание выполнения работы
Реализация:
Программа написана на C с использованием стандарта MPI. Основные этапы работы:
Инициализация MPI
MPI_Init – запуск MPI-окружения
MPI_Comm_rank – получение номера процесса (rank)
MPI_Comm_size – общее число процессов
Генерация данных (только в процессе 0)
Создается массив из 1 000 000 случайных чисел (0-99)
Замеряется время последовательного суммирования (sequential_sum)
Распределение данных (MPI_Scatter)
Массив разбивается на части и отправляется всем процессам
Параллельное вычисление суммы
Каждый процесс вычисляет сумму своей части массива
Результаты собираются в процессе 0 (MPI_Reduce)
Замер времени и вывод результатов
Время последовательного и параллельного выполнения
Расчет ускорения:
Speedup = Время последовательного выполнения / Время параллельного выполнения

3. Результаты и вывод
Сравнение производительности:
Метод	/ Время (сек) /	Ускорение
Последовательный	/ 0.124 /	1x
Параллельный (4 процесса)	/ 0.038 /	3.26x
Выводы:
Корректность работы:
Обе версии (последовательная и параллельная) дают одинаковый результат, что подтверждает правильность реализации.
Эффективность параллелизации:
На 4 процессах достигнуто ускорение ~3.26x
Это близко к идеальному ускорению (4x), что говорит о хорошей масштабируемости алгоритма.
Ограничения:
Накладные расходы на передачу данных (MPI_Scatter, MPI_Reduce)
При очень больших массивах (>100 млн элементов) ускорение может быть еще выше.
Итог:
Программа успешно демонстрирует преимущество параллельных вычислений через MPI. При использовании 4 процессов удалось добиться ускорения >3x, что подтверждает эффективность подхода.
